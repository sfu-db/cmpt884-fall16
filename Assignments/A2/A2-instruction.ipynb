{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Assignment 2: Interactive Analytics](#Assignment-2:-Interactive-Analytics)\n",
    "\t* [Overview](#Overview)\n",
    "\t* [Entity Resolution (ER)](#Entity-Resolution-%28ER%29)\n",
    "\t\t* [Step 0. Upgrade to Reprowd 0.1.1](#Step-0.-Upgrade-to-Reprowd-0.1.1)\n",
    "\t\t* [Step 1. Read Data](#Step-1.-Read-Data)\n",
    "\t\t* [Step 2. Removing Obviously Non-duplicate Pairs](#Step-2.-Removing-Obviously-Non-duplicate-Pairs)\n",
    "\t\t* [Step 3. Active Learning](#Step-3.-Active-Learning)\n",
    "\t\t\t* [Featurization](#Featurization)\n",
    "\t\t\t* [Initialization](#Initialization)\n",
    "\t\t\t* [Interactive Model Training](#Interactive-Model-Training)\n",
    "\t\t\t* [Evaluation](#Evaluation)\n",
    "\t* [Submission](#Submission)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Interactive Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real world is often dirty. Data scientists can spend 80% of their time on data cleaning without doing real analysis. Imagine you are a data scientists. When you get a dirty dataset and find it expensive to clean, what are you going to do?\n",
    "\n",
    "```\n",
    "If you can say \"let's have a try of interactive analytics (e.g., interactive data cleaning, interactive machine learning, interactive visualization)\", I will be so proud of what I have achieved in this course!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will learn how to use active learning to efficiently clean data. More specifically, you will be given a dirty dataset, which has many duplicate records. Your job is to identify the duplicate records. This is essentially an entity resolution problem. After completing this assignment, you should be able to answer the following questions:\n",
    "\n",
    "* How to solve an entity resolution problem?\n",
    "* How to implement an active learning algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Resolution (ER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ER is defined as finding different records that refer to the same real-world entity, e.g., \"iPhone 4-th Generation\" vs. \"iPhone Four\". It is central to data integration and cleaning. The following figure shows the archtecture of an entity resolution solution. It consists of four major steps. **I will provide you the source code for Steps 1, 2, 4. Your job is to implement Step 3.**  \n",
    "\n",
    "<img src=\"img/arch.png\", width=800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0. Upgrade to Reprowd 0.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added a few new features to Reprowd for this assignment. Please make sure to upgrade to Reprowd 0.1.1. \n",
    "\n",
    "```\n",
    "$ git clone https://github.com/sfu-db/reprowd.git\n",
    "$ cd reprowd\n",
    "$ python setup.py install\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the version through `reprowd.__version__` \n",
    "```\n",
    ">>> import reprowd\n",
    ">>> print reprowd.__version__\n",
    "0.1.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [restaurant data](restaurant.csv) is in a CSV file. Here is the code to read it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Rows: 858\n",
      "Header: ['id', 'name', 'address', 'city', 'type']\n",
      "First Row: ['1', \"arnie morton's of chicago\", '435 s. la cienega blv.', 'los angeles', 'american']\n",
      "Second Row: ['2', \"arnie morton's of chicago\", '435 s. la cienega blvd.', 'los angeles', 'steakhouses']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "data = []\n",
    "with open('restaurant.csv', 'rb') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    header = reader.next()\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "print \"Num of Rows:\", len(data)\n",
    "print \"Header:\", header\n",
    "print \"First Row:\", data[0]\n",
    "print \"Second Row:\", data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this dataset, you will find many duplicate records. For example, the first two rows shown above are duplicate. You can check out all duplicate record pairs in the [ground_truth.json](ground_truth.json) file. This file will be used to evaluate your ML model in Step 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Removing Obviously Non-duplicate Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive implementation of entity resolution is to enumerate all $n^2$ pairs and check whether they are duplicate or not. Imagine the table has one million records. It will require to do $10^{12}$ pair comparisons, which is extremely expensive. Thus, the first challenge of entity resolution is how to avoid $n^2$ comparisons. \n",
    "\n",
    "The basic idea is that among $n^2$ pairs, the majority of them look very dissimilar. Thus, we can run a *similarity join* algorithm to remove very dissimilar pairs, and assume that all of the removed pairs are non-duplicate. Note that similarity-join algorithms do not need to do $n^2$ comparisons with the help of inverted indices. You can refer to [this paper (Sec 2)](https://www.cs.sfu.ca/~jnwang/papers/sigmod2012-adaptjoin.pdf) for more detail.  \n",
    "\n",
    "Here is the code. After running the code, you will get 678 similar pairs ordered by their similarity decreasingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Pairs:  367653\n",
      "Num of Similar Pairs:  678\n",
      "The Most Similar Pair:  (['170', \"mary mac's tea room\", '224 ponce de leon ave.', 'atlanta', 'southern/soul'], ['169', \"mary mac's tea room\", '224 ponce de leon ave.', 'atlanta', 'southern'])\n"
     ]
    }
   ],
   "source": [
    "from reprowd.utils.simjoin import *\n",
    "\n",
    "def joinkey_func(row):\n",
    "    # concatenate 'name', 'address', 'city' and 'type', and\n",
    "    # tokensize the concatenated string into a set of words \n",
    "    return wordset(' '.join(row[1:])) \n",
    "\n",
    "key_row_list = [(joinkey_func(row) , row) for row in data]\n",
    "sj = SimJoin(key_row_list)\n",
    "result = sj.selfjoin(0.4)  \n",
    "result.sort(key=lambda x: -x[2])\n",
    "simpairs = [(row1, row2) for (key1, row1), (key2, row2), sim in result] \n",
    "\n",
    "print \"Num of Pairs: \", len(data)*(len(data)-1)/2\n",
    "print \"Num of Similar Pairs: \", len(simpairs)\n",
    "print \"The Most Similar Pair: \", simpairs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a set of similar pairs, what you need to do next is to iteratively train a classifier to decide which pairs are truly duplicate. We are going to use [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression) as our classifier and use [active learning](http://tiny.cc/wm2pgy) to train the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model, the first thing you need to think about is how to featurize data. That is, transforming each similar pair to a feature vector. Please use the following code for featurization. Here, a feature is computed as a similarity value on an attribute. For instance, f1 is the edit similarity of the names of two restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature vector of the first pair:  (1.0, 1.0, 1.0, 1.0, 1.0, 0.6153846153846154)\n"
     ]
    }
   ],
   "source": [
    "from reprowd.utils.simjoin import *\n",
    "\n",
    "# Use this function to transform each pair to a feature vector \n",
    "def featurize(pair):\n",
    "    row1, row2 = pair\n",
    "    \n",
    "    #cleaning\n",
    "    row1 = [alphnum(x.lower()) for x in row1]\n",
    "    row2 = [alphnum(x.lower()) for x in row2] \n",
    "    \n",
    "    # features\n",
    "    f1 = editsim(row1[1], row2[1])\n",
    "    f2 = jaccard_w(row1[1], row2[1])\n",
    "    f3 = editsim(row1[2], row2[2])\n",
    "    f4 = jaccard_w(row1[2], row2[2])\n",
    "    f5 = editsim(row1[3], row2[3])\n",
    "    f6 = editsim(row1[4], row2[4])\n",
    "    \n",
    "    return (f1, f2, f3, f4, f5, f6)\n",
    "\n",
    "print \"The feature vector of the first pair: \", featurize(simpairs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning, all the pairs are unlabeled. To initialize a model, we first pick up ten pairs and then use reprowd to label them. Please use the following code to do the initialization. Note that please set a **distinct project name and short name** to make the code work.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches:  5\n",
      "Number of nonmatches:  5\n"
     ]
    }
   ],
   "source": [
    "from reprowd.crowdcontext import *\n",
    "from reprowd.presenter.text import TextCmp\n",
    "\n",
    "# choose the most/least similar five pairs as initial training data\n",
    "init_pairs = simpairs[:5] + simpairs[-5:]\n",
    "\n",
    "def map_func(row_pair):\n",
    "    row1, row2 = row_pair\n",
    "    return {'obj1': zip(header, row1), 'obj2':zip(header, row2)}\n",
    "\n",
    "cc = CrowdContext()\n",
    "\n",
    "presenter = TextCmp().set_name(\"Finding Duplicate Resturants\") \\\n",
    "                .set_short_name(\"dup-resturant\") \\\n",
    "                .set_question(\"Are they the same restaurant?\") \n",
    "        \n",
    "        \n",
    "crowddata = cc.CrowdData(init_pairs, \"active-ER\") \\\n",
    "                .set_presenter(presenter, map_func) \\\n",
    "                .publish_task().get_result().quality_control(\"mv\")\n",
    "\n",
    "matches = []\n",
    "nonmatches = []\n",
    "for pair, label in zip(crowddata.data['object'], crowddata.data['mv']):\n",
    "    if label == 'Yes':\n",
    "        matches.append(pair)\n",
    "    else:\n",
    "        nonmatches.append(pair)\n",
    "print \"Number of matches: \", len(matches)\n",
    "print \"Number of nonmatches: \", len(nonmatches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive Model Training\n",
    "Here is the only code you need to write in this assignment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeled_pairs = matches + nonmatches\n",
    "unlabeled_pairs = [p for p in simpairs if p not in labeled_pairs]\n",
    "batch_size = 2\n",
    "iter_num = 5\n",
    "\n",
    "#<-- Write Your Code -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Algorithm Description].** The algorithm trains an initial model on `labeled_pairs`. Then, it iteratively trains a model. At each iteration, it first applies the model to `unlabeled_pairs`, and makes a prediction on each unlabled pair along with a probability, where the probability indicates the confidence of the prediction. After that, it selects a batch of most uncertain pairs and publishes them to a crowdsourcing platform (e.g., http://ec2-54-200-84-187.us-west-2.compute.amazonaws.com:5000) using reprowd. After the published pairs are labeled, it updates `labeled_pairs` and `unlabeled_pairs`, and then retrain the model on `labeled_pairs`.\n",
    "\n",
    "**[Input].** \n",
    "- `labeled_pairs`: 10 labeled pairs (by default)\n",
    "- `unlabeled_pairs`: 668 unlabeled pairs (by default)\n",
    "- `iter_num`: 5 (by default)\n",
    "- `batch_size`: 2 (by default)\n",
    "\n",
    "**[Output].** \n",
    "- `model`: A logistic regression model built by scikit-learn\n",
    "\n",
    "\n",
    "**[Requirements and Hints].**\n",
    "  1. Set [n_assignments = 1](http://sfu-db.github.io/reprowd/docs/html/operators.html#reprowd.operators.crowddata.CrowdData.publish_task).\n",
    "  2. Note that the point of this assignment is not to evaluate the performance of crowd workers. So you don't have to collect labels from real-world crowd workers (e.g., mturk). Instead, you can do the labeling tasks by yourself or ask your friends for help. \n",
    "  3. Please use [sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to train the logistic regression model.\n",
    "  4. Our interactive model training process is known as [Active Learning](http://tiny.cc/2qrrgy).\n",
    "  5. If you have any question about the assignment, please ask them in the [Reprowd Google Groups](https://groups.google.com/forum/#!forum/reprowd).  \n",
    "  6. If you find a bug or want to add a new feature to reprowd, please follow the instruction at this [page](http://sfu-db.github.io/reprowd/dev_guide.html). You will get <font color='red'>bonus points</font> by making these contributions. \n",
    "  7. Last but not the least, even if you do not get a chance to file a bug or feature request, you can still make a contribution to the project by simply clicking the <font color='red'>Star</font> on <a href=\"https://github.com/sfu-db/reprowd\">Github</a>. \n",
    "  \n",
    "     <img src=\"img/reprowd-click-star.png\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Precision, Recall](https://en.wikipedia.org/wiki/Precision_and_recall), [F-Score](https://en.wikipedia.org/wiki/F1_score) are commonly used to evaluate an entity-resolution result. After training an model, you can use the following code to evalute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('ground_truth.json') as f:    \n",
    "    true_matches = json.load(f)\n",
    "    \n",
    "\n",
    "def evaluate(identified_matches, true_matches):\n",
    "    n = 0\n",
    "    for (x, y) in identified_matches:\n",
    "        if [x, y] in true_matches or [y, x] in true_matches:\n",
    "            n += 1\n",
    "    precision = n*1.0/len(identified_matches)\n",
    "    recall = n*1.0/len(true_matches)\n",
    "    fscore = 2*precision*recall/(precision+recall)\n",
    "    return (precision, recall, fscore) \n",
    "            \n",
    "\n",
    "sp_features = np.array([featurize(sp) for sp in simpairs])\n",
    "label = model.predict(sp_features)\n",
    "pair_label = zip(simpairs, label)\n",
    "\n",
    "identified_matches = []\n",
    "for pair, label in pair_label:\n",
    "    if label == 1:\n",
    "        identified_matches.append(((pair[0][0], pair[1][0])))\n",
    "        \n",
    "precision, recall, fscore = evaluate(identified_matches, true_matches)\n",
    "\n",
    "print \"Precision:\", precision\n",
    "print \"Recall:\", recall\n",
    "print \"Fscore:\", fscore\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download [er.zip](er.zip). Open `er.ipynb` and complete the code. Submit a zip package, named `er-final.zip`, with `er.ipynb`, `restaurant.csv`, `ground_truth.json`, and `reprowd.db` inside. Make sure others can rerun your code and reproduce your result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
